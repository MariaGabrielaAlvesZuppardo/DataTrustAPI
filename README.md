# DataTrust API

**DataTrust API** Ã© uma plataforma de **engenharia de dados** que valida, governa e expÃµe dados confiÃ¡veis como **Data Products**, utilizando **FastAPI** como camada de consumo.

O projeto foi desenhado para representar um cenÃ¡rio **real de mercado**, cobrindo ingestÃ£o, qualidade de dados, transformaÃ§Ã£o e entrega via API â€” indo muito alÃ©m de um CRUD.

---

## ğŸ¯ Objetivo do Projeto

Demonstrar, de forma prÃ¡tica, habilidades essenciais de uma **Engenheira de Dados**, incluindo:

* IngestÃ£o de dados de fontes pÃºblicas confiÃ¡veis
* ValidaÃ§Ã£o automÃ¡tica de qualidade de dados
* CriaÃ§Ã£o de camadas de dados (raw â†’ trusted)
* GovernanÃ§a bÃ¡sica e versionamento
* ExposiÃ§Ã£o de dados tratados via FastAPI
* Estrutura pronta para escalar para Lakehouse / Data Mesh

---

## ğŸ§  Problema de NegÃ³cio

Em ambientes corporativos, dados frequentemente entram no Data Lake sem validaÃ§Ã£o, resultando em:

* Dashboards inconsistentes
* Quebras de pipeline
* Falta de confianÃ§a nos dados
* Retrabalho constante

O **DataTrust API** resolve esse problema ao garantir que **apenas dados validados e confiÃ¡veis** sejam consumidos por BI, aplicaÃ§Ãµes ou modelos de Machine Learning.

---

## ğŸ“Š Fonte de Dados

**Washington State Department of Labor & Industries**
Dataset pÃºblico sobre acidentes de trabalho nos Estados Unidos.

CaracterÃ­sticas:

* Dados reais
* Fonte governamental norte-americana
* AtualizaÃ§Ã£o periÃ³dica
* Estrutura adequada para anÃ¡lises analÃ­ticas

> A fonte Ã© amplamente utilizada em estudos pÃºblicos e projetos de anÃ¡lise de dados nos EUA.

---

## ğŸ—ï¸ Arquitetura Geral

```
[ Fonte PÃºblica (EUA) ]
        |
        v
[ IngestÃ£o - Raw Layer ]
        |
        v
[ Data Quality - Great Expectations ]
        |
        v
[ Trusted Layer - PostgreSQL ]
        |
        v
[ FastAPI - Data Product ]
```

---

## ğŸ”§ Stack TecnolÃ³gica

### Backend & Dados

* Python 3.11
* FastAPI
* PostgreSQL
* SQLAlchemy
* Pydantic

### Engenharia de Dados

* Pandas
* Great Expectations
* Docker & Docker Compose

### ObservaÃ§Ãµes

* A arquitetura Ã© **Spark-ready** e pode ser facilmente migrada para **Databricks / Delta Lake**.

---

## ğŸ“‚ Estrutura do Projeto

```
data-trust-api/
â”‚
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ load_raw.py
â”‚
â”œâ”€â”€ quality/
â”‚   â””â”€â”€ expectations.py
â”‚
â”œâ”€â”€ transformations/
â”‚   â””â”€â”€ trusted_layer.py
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ db/
â”œâ”€â”€ tests/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ”„ Pipeline de Dados

### 1ï¸âƒ£ IngestÃ£o (Raw Layer)

* Coleta de dados via download automatizado
* PersistÃªncia dos dados brutos
* Nenhuma transformaÃ§Ã£o aplicada

ExecuÃ§Ã£o:

```bash
python ingestion/load_raw.py
```

---

### 2ï¸âƒ£ Data Quality

ValidaÃ§Ãµes automÃ¡ticas utilizando **Great Expectations**:

* ValidaÃ§Ã£o de schema
* Percentual mÃ¡ximo de valores nulos
* VerificaÃ§Ã£o de duplicidade
* ValidaÃ§Ã£o de ranges (datas, IDs)

Resultado das validaÃ§Ãµes:

| dataset | total_rows | failed_rules | quality_score |
| ------- | ---------- | ------------ | ------------- |

Esses metadados ficam disponÃ­veis para consumo via API.

---

### 3ï¸âƒ£ TransformaÃ§Ãµes (Trusted Layer)

* Limpeza de dados
* NormalizaÃ§Ã£o de colunas
* CriaÃ§Ã£o de agregaÃ§Ãµes analÃ­ticas

Exemplos:

* Acidentes por ano
* Acidentes por setor industrial

---

## ğŸš€ FastAPI como Data Product

A API expÃµe **dados prontos para consumo**, com contratos bem definidos.

### Principais Endpoints

```http
GET /v1/accidents/summary?year=2023
GET /v1/accidents/by-industry
GET /v1/quality/latest
GET /health
```

CaracterÃ­sticas:

* Versionamento da API
* Contratos via Pydantic
* SeparaÃ§Ã£o clara entre camada de serviÃ§o e roteamento

---

## ğŸ›¡ï¸ GovernanÃ§a e Boas PrÃ¡ticas

* Versionamento de dados e API
* Contratos explÃ­citos de dados
* Logs de execuÃ§Ã£o
* Healthcheck para observabilidade

---

## ğŸ§ª Testes

* Testes unitÃ¡rios para regras de qualidade
* Testes de contrato da API

---

## ğŸ“ˆ PossÃ­veis EvoluÃ§Ãµes

* AutenticaÃ§Ã£o JWT
* Cache com Redis
* Airflow / Prefect para orquestraÃ§Ã£o
* MÃ©tricas com Prometheus + Grafana
* Delta Lake e arquitetura Lakehouse
* ImplementaÃ§Ã£o de conceitos de Data Mesh

---

## ğŸ‘©â€ğŸ’» Autora

**Gabriela (Zuppardo)**
Engenheira de Dados

Projeto desenvolvido com foco em **engenharia de dados moderna**, **governanÃ§a** e **entrega de valor via dados**.

---

## ğŸ“Œ ObservaÃ§Ã£o Final

Este projeto foi construÃ­do com foco em **cenÃ¡rios reais de mercado**, priorizando clareza arquitetural, boas prÃ¡ticas e escalabilidade, sendo ideal para demonstraÃ§Ã£o tÃ©cnica em processos seletivos de Engenharia de Dados.
